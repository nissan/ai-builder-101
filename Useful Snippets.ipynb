{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f67c6b3-3132-402a-b59b-3d9f17e05eab",
   "metadata": {},
   "source": [
    "# Useful snippets from other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aeb11d-73ba-49a2-8878-7dc8e92499d3",
   "metadata": {},
   "source": [
    "## Printing enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363bfcba-bfb6-4dd5-abcd-9890d7c45274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam', 'eggs', 'lumberjack', 'knights', 'ni']\n",
      "['spam', 'eggs',\n",
      " 'lumberjack',\n",
      " 'knights', 'ni']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "results = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']\n",
    "print(results)\n",
    "pprint.pprint(results, width=20, compact=True)\n",
    "# See docs at https://docs.python.org/3/library/pprint.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa657861-9e19-4db4-b716-55f19690f25c",
   "metadata": {},
   "source": [
    "## Restart kernel after install of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b592dce0-9b6b-47fc-8fd2-cb91c54ece12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bb6e9-57a2-4990-a0b4-8b02896e44b2",
   "metadata": {},
   "source": [
    "## Setting OpenAI API key if not present in environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194de3ef-9f1d-49ad-8235-6948b39e12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6fb354-e933-40be-a755-7e68b3b41eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# Configuring the environment variable OPENAI_API_KEY\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    # OR set the key here as a variable\n",
    "    openai.api_key = getpass.getpass(\"OpenAI API Key:\")\n",
    "    \n",
    "assert len(openai.Model.list()[\"data\"]) > 0 #Will generate an error if the key is not valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c1b95-c6c8-45c6-bed3-459638c54937",
   "metadata": {},
   "source": [
    "## Testing if you have a CUDA device setup with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8684695a-10aa-4cf1-addd-649a811d4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ed08394-d6f4-4a33-859f-2f31e7c6ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Alternative from pytorch docs that allows for Mac GPU training as well\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "print(f\"GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dae227-bf54-4dca-9e27-5e27d6d8eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc42a4-84a3-4518-a574-28e72ee8dcd7",
   "metadata": {},
   "source": [
    "## To have some 'useful' raw data for RAG stuff, I extracted my own bookmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a508d65-c82b-44e7-b835-d0bde7815bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def extract_chrome_bookmarks():\n",
    "    # Define the path to the Chrome bookmarks file\n",
    "    # This is the default location on Windows. You may need to adjust this for other operating systems. Also may need to change the user to match yours\n",
    "    path_to_bookmarks = \"/mnt/c/Users/nissa/AppData/Local/Google/Chrome/User Data/Default/Bookmarks\"\n",
    "\n",
    "    # Ensure the file exists\n",
    "    if not os.path.exists(path_to_bookmarks):\n",
    "        print(\"The bookmarks file was not found at the specified location. Ensure Chrome is installed and you have bookmarks saved.\")\n",
    "        return []\n",
    "\n",
    "    # Load the JSON data\n",
    "    with open(path_to_bookmarks, 'r', encoding='utf-8') as file:\n",
    "        bookmarks_data = json.load(file)\n",
    "\n",
    "    # Define a recursive function to extract bookmarks\n",
    "    def extract_from_node(node):\n",
    "        if 'url' in node:\n",
    "            return [(node['name'], node['url'])]\n",
    "        else:\n",
    "            urls = []\n",
    "            if 'children' in node:\n",
    "                for child in node['children']:\n",
    "                    urls.extend(extract_from_node(child))\n",
    "            return urls\n",
    "\n",
    "    # Extract the bookmarks\n",
    "    bookmarks = extract_from_node(bookmarks_data['roots']['bookmark_bar']) \n",
    "    bookmarks += extract_from_node(bookmarks_data['roots']['other'])  # Other bookmarks\n",
    "\n",
    "    return bookmarks\n",
    "\n",
    "bookmarks_list = extract_chrome_bookmarks()\n",
    "# Run below if you want to be sure your bookmarks are imported as you expect\n",
    "# for title, url in bookmarks_list:\n",
    "    # print(f\"{title}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0d4e6-1eaa-478a-b72d-8f65d9d79a49",
   "metadata": {},
   "source": [
    "## Importing data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd090f1-fa75-47e7-8507-5943049b6742",
   "metadata": {},
   "source": [
    "> Using [Jeremy Howard's notebook](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/) as a learning sample starting point for my modified settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affa2bc8-2f50-475f-9ea9-26780fb03f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd30e7ac-89cd-484e-aadd-3f1c4c4a12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for working with paths in Python, Jeremy Howard recommends using `pathlib.Path`\n",
    "from pathlib import Path\n",
    "\n",
    "cred_path = Path('~/.kaggle/kaggle.json').expanduser() #If you don't have the kaggle.json read about this at https://www.kaggle.com/docs/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d406c6-1d80-4d7f-b270-ac70ae98772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_name='us-patent-phrase-to-phrase-matching' #change to match competition name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa9ddba-6494-4fcc-863a-6826e59e2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f'data/{competition_name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcdce31-24bc-4e6f-8b5f-cfc5be620134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def download_competition_data(competition_name):\n",
    "    # Create 'data' folder if it doesn't exist\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    # Run the Kaggle CLI command to download the competition data into 'data' folder\n",
    "    cmd = f\"kaggle competitions download -c {competition_name} -p data\"\n",
    "    subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffe2716-fcec-4f79-aeab-1d3eaf2d66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '') # This is to check if this notebook is running on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda56b46-461c-427f-a4e4-c85f36889c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note if an error, make sure to visit the competition page and accept the rules so you can download the data\n",
    "if not iskaggle and not path.exists():\n",
    "    import zipfile,kaggle\n",
    "    # Replace 'your-competition-name-here' with the desired competition's name\n",
    "    download_competition_data(competition_name)\n",
    "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c4518f-95ac-4e13-bd4f-c77bb1abf1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c3626-1c40-49b9-b52c-5cbd3f06e108",
   "metadata": {},
   "source": [
    "## Exploring data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1085e05-5aab-4bef-bf6d-05b455ae61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ad1c50-9ad3-4765-a05e-dd5aa9a737be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51c71ec-abd1-44f9-91a9-121623dcca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ac9697-aeb7-4d39-9b33-3381a511a407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d6f34-1ee7-4698-9d35-8bf5919619a2",
   "metadata": {},
   "source": [
    "## Use only my selected GPU (Prevents out of memory crashes when fine tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e35c7b-55e5-4435-8810-b147567d5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 11 09:18:45 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98.01              Driver Version: 536.99       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     On  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   62C    P8               7W /  80W |    723MiB /  6144MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX               On  | 00000000:14:00.0 Off |                  N/A |\n",
      "| 41%   28C    P8               1W / 280W |    116MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        20      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        20      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        21      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        23      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        26      G   /Xwayland                                 N/A      |\n",
      "|    1   N/A  N/A        20      G   /Xwayland                                 N/A      |\n",
      "|    1   N/A  N/A        20      G   /Xwayland                                 N/A      |\n",
      "|    1   N/A  N/A        21      G   /Xwayland                                 N/A      |\n",
      "|    1   N/A  N/A        23      G   /Xwayland                                 N/A      |\n",
      "|    1   N/A  N/A        26      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4a61ab-e627-46bf-9a28-8f931a6ec0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cdea30-e780-4110-8f2c-41b532e6c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? True\n",
      "Is cuDNN version: 8700\n",
      "cuDNN enabled?  True\n",
      "Device count? 1\n",
      "Current device? 0\n",
      "Device name?  NVIDIA TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Is cuda available?\", torch.cuda.is_available())\n",
    "\n",
    "print(\"Is cuDNN version:\", torch.backends.cudnn.version())\n",
    "\n",
    "print(\"cuDNN enabled? \", torch.backends.cudnn.enabled)\n",
    "\n",
    "print(\"Device count?\", torch.cuda.device_count())\n",
    "\n",
    "print(\"Current device?\", torch.cuda.current_device())\n",
    "\n",
    "print(\"Device name? \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be789d9a-c675-45b6-8767-6b5d133b5421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
